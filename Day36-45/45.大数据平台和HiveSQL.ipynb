{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca901dfb",
   "metadata": {},
   "source": [
    "## Hive简介\n",
    "\n",
    "[Hive](https://hive.apache.org/) 是 Facebook 开源的一款基于 Hadoop 的数据仓库工具，目前由 Apache 软件基金会维护，它是应用最广泛的大数据处理解决方案，它能将 SQL 查询转变为 MapReduce（Google提出的一个软件架构，用于大规模数据集的并行运算）任务，对 SQL 提供了完美的支持，能够非常方便的实现大数据统计。\n",
    "\n",
    "<img src=\"res/sql_to_mr.png\" style=\"zoom:50%;\">\n",
    "\n",
    "<img src=\"res/HADOOP-ECOSYSTEM-Edureka.png\">\n",
    "\n",
    "> **说明**：可以通过<https://www.edureka.co/blog/hadoop-ecosystem>来了解 Hadoop 生态圈。\n",
    "\n",
    "如果要简单的介绍 Hive，那么以下两点是其核心：\n",
    "\n",
    "1. 把 HDFS 中结构化的数据映射成表。\n",
    "2. 通过把 HQL 进行解析和转换，最终生成一系列基于 Hadoop 的 MapReduce 任务或 Spark 任务，通过执行这些任务完成对数据的处理。也就是说，即便不学习 Java、Scala 这样的编程语言，一样可以实现对数据的处理。\n",
    "\n",
    "Hive的应用场景。\n",
    "\n",
    "<img src=\"res/what_hive_can_do.png\" style=\"zoom:50%;\">\n",
    "\n",
    "<img src=\"res/what_hive_can_not_do.png\" style=\"zoom:35%;\">\n",
    "\n",
    "Hive和传统关系型数据库的对比如下图和下表所示。\n",
    "\n",
    "<img src=\"res/hive_vs_rdbms.png\" style=\"zoom:50%;\">\n",
    "\n",
    "|          | Hive              | RDBMS        |\n",
    "| -------- | ----------------- | ------------ |\n",
    "| 查询语言 | HQL               | SQL          |\n",
    "| 存储数据 | HDFS              | 本地文件系统 |\n",
    "| 执行方式 | MapReduce / Spark | Executor     |\n",
    "| 执行延迟 | 高                | 低           |\n",
    "| 数据规模 | 大                | 小           |\n",
    "\n",
    "### 准备工作\n",
    "\n",
    "1. 搭建如下图所示的大数据平台。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"res/20220210080638.png\" style=\"zoom:60%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb77177",
   "metadata": {},
   "source": [
    "2. 通过Client节点（跳板机）访问大数据平台。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"res/20220210080655.png\" style=\"zoom:50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d297f",
   "metadata": {},
   "source": [
    "3. 创建文件Hadoop的文件系统。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "```Shell\n",
    "hdfs dfs -mkdir /user/root\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f99061e",
   "metadata": {},
   "source": [
    "4. 将准备好的数据文件拷贝到Hadoop文件系统中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc651ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "```Shell\n",
    "hdfs dfs -put /home/ubuntu/data/* /user/root\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b43099",
   "metadata": {},
   "source": [
    "5. 进入 hive 命令行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57724d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "```Shell\n",
    "hive\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee950180",
   "metadata": {},
   "source": [
    "### 建库建表\n",
    "\n",
    "1. 创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a942424",
   "metadata": {},
   "outputs": [],
   "source": [
    "```SQL\n",
    "create database eshop;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3767299",
   "metadata": {},
   "source": [
    "2. 删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "```SQL\n",
    "drop database eshop cascade;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690cd3d",
   "metadata": {},
   "source": [
    "3. 切换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadeb664",
   "metadata": {},
   "outputs": [],
   "source": [
    "```SQL\n",
    "use eshop;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5519fca8",
   "metadata": {},
   "source": [
    "#### 数据类型\n",
    "\n",
    "Hive的数据类型如下所示。\n",
    "\n",
    "<img src=\"res/hive_data_types.png\" style=\"zoom:50%;\">\n",
    "\n",
    "基本数据类型：\n",
    "\n",
    "| 数据类型  | 占用空间 | 支持版本 |\n",
    "| --------- | -------- | -------- |\n",
    "| tinyint   | 1-Byte   |          |\n",
    "| smallint  | 2-Byte   |          |\n",
    "| int       | 4-Byte   |          |\n",
    "| bigint    | 8-Byte   |          |\n",
    "| boolean   |          |          |\n",
    "| float     | 4-Byte   |          |\n",
    "| double    | 8-Byte   |          |\n",
    "| string    |          |          |\n",
    "| binary    |          | 0.8版本  |\n",
    "| timestamp |          | 0.8版本  |\n",
    "| decimal   |          | 0.11版本 |\n",
    "| char      |          | 0.13版本 |\n",
    "| varchar   |          | 0.12版本 |\n",
    "| date      |          | 0.12版本 |\n",
    "\n",
    "复合数据类型：\n",
    "\n",
    "| 数据类型 | 描述                     | 例子                                          |\n",
    "| -------- | ------------------------ | --------------------------------------------- |\n",
    "| struct   | 和C语言中的结构体类似    | `struct<first_name:string, last_name:string>` |\n",
    "| map      | 由键值对构成的元素的集合 | `map<string,int>`                             |\n",
    "| array    | 具有相同类型的变量的容器 | `array<string>`                               |\n",
    "\n",
    "4. 创建内部表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92afb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "```SQL\n",
    "create table if not exists dim_user_info \n",
    "(\n",
    "user_id string,\n",
    "user_name string, \n",
    "sex string,\n",
    "age int,\n",
    "city string,\n",
    "firstactivetime string,\n",
    "level int,\n",
    "extra1 string,\n",
    "extra2 map<string,string>\n",
    ")\n",
    "row format delimited fields terminated by '\\t'\n",
    "collection items terminated by ','\n",
    "map keys terminated by ':'\n",
    "lines terminated by '\\n'\n",
    "stored as textfile;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edbc4a2",
   "metadata": {},
   "source": [
    "5. 加载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "```SQL\n",
    "load data local inpath '/home/ubuntu/data/user_info/user_info.txt' overwrite into table dim_user_info;\n",
    "```\n",
    "\n",
    "或\n",
    "\n",
    "```SQL\n",
    "load data inpath '/user/root/user_info.txt' overwrite into table dim_user_info;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3746bc",
   "metadata": {},
   "source": [
    "6. 创建分区表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "```SQL\n",
    "create table if not exists fact_user_trade \n",
    "(\n",
    "user_name string,\n",
    "piece int,\n",
    "price double,\n",
    "pay_amount double,\n",
    "goods_category string,\n",
    "pay_time bigint\n",
    ")  \n",
    "partitioned by (dt string)\n",
    "row format delimited fields terminated by '\\t';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d578126",
   "metadata": {},
   "source": [
    "7. 提供分区数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "```Shell\n",
    "hdfs dfs -put /home/ubuntu/data/user_trade/* /user/hive/warehouse/eshop.db/fact_user_trade\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b72c4d",
   "metadata": {},
   "source": [
    "8. 设置动态分区。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c42235",
   "metadata": {},
   "outputs": [],
   "source": [
    "```SQL\n",
    "set hive.exec.dynamic.partition=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions=10000;\n",
    "set hive.exec.max.dynamic.partitions.pernode=10000;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc683e9c",
   "metadata": {},
   "source": [
    "9. 修复分区。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7611613",
   "metadata": {},
   "outputs": [],
   "source": [
    "```SQL\n",
    "msck repair table fact_user_trade;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b0e72",
   "metadata": {},
   "source": [
    "### 查询\n",
    "\n",
    "#### 基本语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863c997",
   "metadata": {
    "attributes": {
     "classes": [
      "SQL"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "-- 查询北京女用户的姓名取前10个\n",
    "select user_name from dim_user_info where city='beijing' and sex='female' limit 10;\n",
    "\n",
    "-- 查询2019年3月24日购买了food类商品的用户名、购买数量和支付金额（不聚合）\n",
    "select user_name, piece, pay_amount from fact_user_trade where dt='2019-03-24' and goods_category='food';\n",
    "\n",
    "-- 统计用户 ELLA 在2018年的总支付金额和最近最远两次消费间隔天数\n",
    "select sum(pay_amount) as total, datediff(max(from_unixtime(pay_time, 'yyyy-MM-dd')), min(from_unixtime(pay_time, 'yyyy-MM-dd'))) from fact_user_trade where year(dt)='2018' and user_name='ELLA';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c226f6d",
   "metadata": {},
   "source": [
    "#### group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7839d",
   "metadata": {
    "attributes": {
     "classes": [
      "SQL"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "-- 查询2019年1月到4月，每个品类有多少人购买，累计金额是多少\n",
    "select goods_category, count(distinct user_name) as total_user, sum(pay_amount) as total_pay from fact_user_trade where dt between '2019-01-01' and '2019-04-30' group by goods_category;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ec9a9",
   "metadata": {
    "attributes": {
     "classes": [
      "SQL"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "-- 查询2019年4月支付金额超过5万元的用户\n",
    "select user_name, sum(pay_amount) as total from fact_user_trade where dt between '2019-04-01' and '2019-04-30' group by user_name having sum(pay_amount) > 50000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d537c75",
   "metadata": {
    "attributes": {
     "classes": [
      "hive"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "-- 查询2018年购买的商品品类在两个以上的用户数\n",
    "select count(tmp.user_name) from (select user_name, count(distinct goods_category) as total from fact_user_trade where year(dt)='2018' group by user_name having count(distinct goods_category)>2) tmp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24040251",
   "metadata": {},
   "source": [
    "#### order by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a51ba",
   "metadata": {
    "attributes": {
     "classes": [
      "SQL"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "-- 查询2019年4月支付金额最多的用户前5名\n",
    "select user_name, sum(pay_amount) as total from fact_user_trade where dt between '2019-04-01' and '2019-04-30' group by user_name order by total desc limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b56e5",
   "metadata": {},
   "source": [
    "#### 常用函数\n",
    "\n",
    "1. `from_unixtime`：将时间戳转换成日期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82982a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "```hive\n",
    "select from_unixtime(pay_time, 'yyyy-MM-dd hh:mm:ss') from fact_user_trade limit 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047a220",
   "metadata": {},
   "source": [
    "2. `unix_timestamp`：将日期转换成时间戳\n",
    "\n",
    "3. `datediff`：计算两个日期的时间差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b993f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "```Hive\n",
    "-- 用户首次激活时间与设定参照时间的间隔\n",
    "select user_name, datediff('2019-4-1', to_date(firstactivetime)) from dim_user_info limit 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c13d82",
   "metadata": {},
   "source": [
    "4. `if`：根据条件返回不同的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ec864",
   "metadata": {},
   "outputs": [],
   "source": [
    "```Hive\n",
    "-- 统计不同年龄段的用户数\n",
    "select case when age < 20 then '20岁以下' when age < 30 then '30岁以下' when age < 40 then '40岁以下' else '40岁以上' end as age_seg, count(distinct user_id) as total from dim_user_info group by case when age < 20 then '20岁以下' when age < 30 then '30岁以下' when age < 40 then '40岁以下' else '40岁以上' end;\n",
    "```\n",
    "\n",
    "```Hive\n",
    "-- 不同性别高级等用户数量\n",
    "select sex, if(level > 5, '高', '低') as level_type, count(distinct user_id) as total from dim_user_info group by sex, if(level > 5, '高', '低');\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe68bd94",
   "metadata": {},
   "source": [
    "5. `substr`：字符串取子串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "```Hive\n",
    "-- 统计每个月激活的新用户数\n",
    "select substr(firstactivetime, 1, 7) as month, count(distinct user_id) as total from dim_user_info group by substr(firstactivetime, 1, 7);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6f216",
   "metadata": {},
   "source": [
    "6. `get_json_object`：从JSON字符串中取出指定的`key`对应的`value`，如：`get_json_object(info, '$.first_name')`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "```Hive\n",
    "-- 统计不同手机品牌的用户数\n",
    "select get_json_object(extra1, '$.phonebrand') as phone, count(distinct user_id) as total from user_info group by get_json_object(extra1, '$.phonebrand');\n",
    "\n",
    "select extra2['phonebrand'] as phone, count(distinct user_id) as total from user_info group by extra2['phonebrand'];\n",
    "```\n",
    "\n",
    "> 说明：MySQL对应的函数名字叫`json_extract`。"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
